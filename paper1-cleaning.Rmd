---
title: "gtrends_cleaning"
author: "Kelsey Gonzalez"
date: "2/7/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, glue, here, vroom, gtrendsR,
               lubridate, zoo)

```

# Functions
```{r}
find_mondays <- function(year) {
  mondays <- seq(ymd(glue("{year}-01-01")),ymd(glue("{year}-12-31")),by="1 day")
  mondays <- mondays[wday(mondays,label = TRUE) == "Mon" & mondays < today() - 7]
  return(mondays)
}
find_initial_trends <- function(keyword, period_list){
  period_list <- as.character(period_list)
  
  trends <- tibble(location = character(),
                   hits = numeric(),
                   keyword = character(),
                   date = character())
  
  for (period in period_list){ 
    ppl7<- as.character(ymd(period) + 7)
    
    trends <- gtrends(
      keyword = keyword,
      geo = "US",
      time = paste(period, ppl7),
      gprop = "web",
      category = 0,
      hl = "en-US")$interest_by_dma %>%
      tibble() %>%
      mutate(date = period,
             hits = as.numeric(hits)) %>% 
      select(-c(geo, gprop)) %>%
      bind_rows(trends)
  }
  
  return(trends)
}
find_scale_point <- function(keyword, year){
  if (year(today()) == year) {
    span <- glue("{year}-01-01 {as.character(today() - 7)}")
    } else {
      span <- glue("{year}-01-01 {year}-12-31")
    }
  
  if (nchar(span) != 21) stop('incorrect span')
  
  print(glue("keyword = {keyword}"))
  print(glue("span = {span}"))
  
  rescale <- gtrends(
    keyword = keyword,
    geo = "US-CA-803",
    time = span,
    gprop = "web",
    category = 0,
    hl = "en-US", 
    onlyInterest = TRUE, 
    low_search_volume = FALSE)$interest_over_time %>% 
    tibble()  %>% 
    mutate(date = ymd(date(date))+1,
           hits = ifelse(hits < 1, NA, hits)) %>%
    fill(hits)%>% 
    select(-c(gprop, keyword, geo, time, category)) %>% 
    rename(hits_rescale = hits)
  
  if (rescale %>% drop_na() %>% nrow() == 0) stop('no rows of data')
  return(rescale)
}
rescale_trends <- function(trends, rescale){
  rescale_ratio <- rescale %>%
    mutate(location = 'Los Angeles CA',
           hits_rescale = replace_na(hits_rescale, 0),
           hits_rescale = ifelse(hits_rescale == 0, 0.0001, hits_rescale)) %>% 
    left_join(trends %>% 
                 mutate(date = ymd(date)), by = c('date', 'location'))  %>% 
    mutate(rescale_ratio = hits_rescale/hits)  %>% 
    select(date, rescale_ratio)
  
  trends <- trends %>% 
    mutate(date = ymd(date)) %>% 
    group_by(location) %>% 
    fill(hits) %>%
    ungroup() %>% 
    left_join(rescale_ratio, by = "date") %>% 
    mutate(hits_transformed_a = hits * rescale_ratio)
  return(trends)
}
find_year_trends <- function(keyword, year){
  trends <- find_initial_trends(keyword, find_mondays(year))
  rescaled<- find_scale_point(keyword, year)
  rescaled_trends <- rescale_trends(trends, rescaled)
  
  rescaled_trends <- rescaled_trends %>% 
    mutate(location = str_to_upper(location),
           location = str_replace_all(location,"-", " - "),
           location = str_replace_all(location,",", ""),
           location = str_replace_all(location,"\\s(\\w{2})\\b", " \\(\\1\\)")) %>% 
    select(DMA_google = location, !!keyword := hits_transformed_a, date)
  
  return(rescaled_trends)
}


```

```{r find_cross_sectional_trends}
find_cross_sectional_trends <- function(keyword, date_begin, span_length = 1){
  ppl <- as.character(ymd(date_begin) + span_length)

  print(glue("keyword = {keyword}"))
  print(glue("span = {date_begin} - {ppl}"))
  
  trends <- gtrends(
    keyword = keyword,
    geo = "US",
    time = paste(date_begin, ppl),
    gprop = "web",
    category = 0,
    hl = "en-US")$interest_by_dma %>%
    tibble() %>%
    mutate(date = date_begin,
           hits = as.numeric(hits)) %>% 
    select(-c(geo, gprop)) %>% 
    mutate(location = str_to_upper(location),
           location = str_replace_all(location,"-", " - "),
           location = str_replace_all(location,",", ""),
           location = str_replace_all(location,"\\s(\\w{2})\\b", " \\(\\1\\)"))
  
  return(trends)
  
}
```


# dma keys
```{r}
# bringing in DMA fox new search from
# https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/IVXEHT/A56RIW&version=7.4
dma <- read_csv(here("data", "county_dma.csv")) %>%
    mutate(FIPS_state = str_pad(STATEFP, 2, pad = "0"),
         FIPS_county = str_pad(CNTYFP, 3, pad = "0"),
         FIPS = paste0(FIPS_state, FIPS_county)) %>%
  select(FIPS, DMA, STATE, COUNTY)

# I made this file for the various inconsistencies between the two
dma_key <- read_csv(here("data","google_dma_key.csv")) 

dma <- dma %>%
  full_join(dma_key)
```


# attitudinal
• Vaccine Hesitancy
		○ https://data.cdc.gov/Vaccinations/Vaccine-Hesitancy-for-COVID-19-County-and-local-es/q9mh-h2tw/data
		
cross-sectional
dates - March 3, 2021 – March 15, 2021
```{r}
find_cross_sectional_trends('trend', '2021-03-03', 12)
```



• Mask Usage
		○ New York Times Survey
		○ https://github.com/nytimes/covid-19-data/tree/master/mask-use

cross-sectional
July 2 and July 14, 2020
```{r}
find_cross_sectional_trends('trend', '2020-07-02', 12)
```


# health
## Covid Rates
		○ https://github.com/nytimes/covid-19-data/tree/master/rolling-averages
longitudinal
dates - 

```{r}
covid_rates <- vroom('https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-counties-2020.csv') %>% bind_rows(vroom('https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-counties-2021.csv')) %>% 
  mutate(wday = lubridate::wday(date, label=TRUE),
         fips = str_sub(geoid, start = -5)) %>% 
  filter(wday == "Mon") %>% 
  select(fips, date, county, state, covid_rate = cases_avg_per_100k)


covid_gtrend <- find_year_trends('Covid-19', 2020) %>% 
  rowbind(find_year_trends('Covid-19', 2021))

find_year_trends('Cant smell', '2020-01-01', 365)
find_year_trends('Covid-19', '2021-01-01', 365)
```

## Suicide
		○ https://wonder.cdc.gov/mcd.html 
		○ Multiple Cause of Death Data 2019 (see notes for which variables count)
dates - 2019 cross sectional inclusive

<!-- TODO need new wonder file, this one only has 1k counties??  -->

```{r suicide}
suicide_measures <- read_delim(here('data','suicide',
                                    'Multiple Cause of Death, 2018-2019, Single Race.txt')) %>% 
  janitor::clean_names() %>% 
  filter(is.na(notes)) %>% 
  select(fips = county_code, county, deaths, population, crude_rate)

suicide_gtrends <- find_cross_sectional_trends(c('suicide', 'depression', 'suicide hotline'), 
                                               '2019-01-01', 365) %>%   
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date) %>% 
  mutate(location = str_to_lower(location))

suicide <- suicide_measures %>% 
  left_join(select(dma, FIPS, DMA_google), by = c('fips' = 'FIPS')) %>% 
  full_join(suicide_gtrends, by = c('DMA_google' = 'location'))  


  select(dma = DMA_google,
         fips = county_fips, 
         clinton_p, `Hilary Clinton`, trump_p, `Donald Trump`)
```


# political
• Presidential results
https://github.com/tonmcg/US_County_Level_Election_Results_08-20
```{r pres_results}
pres_2016_results <- read_csv('https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2016_US_County_Level_Presidential_Results.csv') %>% 
  select(county_name, county_fips = combined_fips, 
         totalvotes = total_votes, clinton = votes_dem, trump = votes_gop) %>% 
    mutate(county_fips = str_pad(county_fips, 5, pad = 0),
           clinton_p = clinton / totalvotes,
         trump_p = trump / totalvotes)


pres_2020_results <- read_csv('https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv') %>% 
  select(state = state_name, county_name, county_fips, 
         totalvotes = total_votes, biden = votes_dem, trump = votes_gop) %>% 
    mutate(biden_p = biden / totalvotes,
         trump_p = trump / totalvotes)
```
```{r pres_gtrend}
pres_2020_gtrend <- find_cross_sectional_trends(c('Joe Biden', 'Donald Trump'), '2020-01-01', 307) %>% 
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date)


pres_2016_gtrend <- find_cross_sectional_trends(c('Hilary Clinton', 'Donald Trump'), '2016-01-01', 307) %>% 
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date)
```
```{r}
pres_2016 <- pres_2016_results %>% 
  inner_join(select(dma, FIPS, DMA_google), by = c('county_fips' = 'FIPS')) %>%
  left_join(pres_2016_gtrend, by = c('DMA_google' = 'location')) %>%
  select(dma = DMA_google,
         fips = county_fips, 
         clinton_p, `Hilary Clinton`, trump_p, `Donald Trump`)
  
pres_2016 %>% ggplot(aes(x = trump_p, y = `Donald Trump`)) + geom_jitter() + geom_smooth()
pres_2016 %>% ggplot(aes(x = clinton_p, y = `Hilary Clinton`)) + geom_jitter()

pres_2020 <- pres_2020_results %>% 
  inner_join(select(dma, FIPS, DMA_google), by = c('county_fips' = 'FIPS')) %>% 
  left_join(pres_2020_gtrend, by = c('DMA_google' = 'location')) %>% 
  select(dma = DMA_google,
         fips = county_fips, 
         biden_p, `Joe Biden`, trump_p, `Donald Trump`)

pres_2020 %>% ggplot(aes(x = biden_p, y = Joe Biden`)) + geom_jitter() + geom_smooth()
pres_2020 %>% ggplot(aes(x = trump_p, y = `Donald Trump`)) + geom_jitter() + geom_smooth()

rm(list = c("pres_2016_results", "pres_2016_gtrend",
            "pres_2020_results", "pres_2020_gtrend"))

