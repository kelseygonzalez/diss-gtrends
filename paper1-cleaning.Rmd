---
title: "gtrends_cleaning"
author: "Kelsey Gonzalez"
date: "2/7/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, glue, here, vroom, gtrendsR,
               lubridate, zoo)

```

# Functions
```{r find_year_trends}
find_mondays <- function(year) {
  print('finding mondays')
  mondays <- seq(ymd(glue("{year}-01-01")),ymd(glue("{year}-12-31")),by="1 day")
  mondays <- mondays[wday(mondays,label = TRUE) == "Mon" & mondays < today() - 7]
  return(mondays)
}
find_initial_trends <- function(keyword, period_list){
  print(glue("find trends for '{keyword}'"))

  period_list <- as.character(period_list)
  
  trends <- tibble(location = character(),
                   hits = numeric(),
                   keyword = character(),
                   date = character())
  
  for (period in period_list){ 
    ppl7<- as.character(ymd(period) + 7)
    
    trends <- gtrends(
      keyword = keyword,
      geo = "US",
      time = paste(period, ppl7),
      gprop = "web",
      category = 0,
      hl = "en-US")$interest_by_dma %>%
      tibble() %>%
      mutate(date = period,
             hits = as.numeric(hits)) %>% 
      select(-c(geo, gprop)) %>%
      bind_rows(trends)
  }
  
  return(trends)
}
find_scale_point <- function(keyword, year){
  print('finding relevant scale point, using US-CA-803')
  if (year(today()) == year) {
    span <- glue("{year}-01-01 {as.character(today() - 7)}")
    } else {
      span <- glue("{year}-01-01 {year}-12-31")
    }
  
  if (nchar(span) != 21) stop('incorrect span')
  
  print(glue("keyword = {keyword}"))
  print(glue("span = {span}"))
  
  rescale <- gtrends(
    keyword = keyword,
    geo = "US-CA-803",
    time = span,
    gprop = "web",
    category = 0,
    hl = "en-US", 
    onlyInterest = TRUE, 
    low_search_volume = FALSE)$interest_over_time %>% 
    tibble()  %>% 
    mutate(date = ymd(date(date))+1,
           hits = ifelse(hits < 1, NA, hits)) %>%
    fill(hits)%>% 
    select(-c(gprop, keyword, geo, time, category)) %>% 
    rename(hits_rescale = hits)
  
  if (rescale %>% drop_na() %>% nrow() == 0) stop('no rows of data')
  return(rescale)
}
rescale_trends <- function(trends, rescale){
  print('rescaling trends')
  rescale_ratio <- rescale %>%
    mutate(location = 'Los Angeles CA',
           hits_rescale = replace_na(hits_rescale, 0),
           hits_rescale = ifelse(hits_rescale == 0, 0.0001, hits_rescale)) %>% 
    left_join(trends %>% 
                 mutate(date = ymd(date)), by = c('date', 'location'))  %>% 
    mutate(rescale_ratio = hits_rescale/hits)  %>% 
    select(date, rescale_ratio)
  
  trends <- trends %>% 
    mutate(date = ymd(date)) %>% 
    group_by(location) %>% 
    fill(hits) %>%
    ungroup() %>% 
    left_join(rescale_ratio, by = "date") %>% 
    mutate(hits_transformed_a = hits * rescale_ratio)
  return(trends)
}
find_year_trends <- function(keyword, year){
  trends <- find_initial_trends(keyword, find_mondays(year))
  rescaled<- find_scale_point(keyword, year)
  rescaled_trends <- rescale_trends(trends, rescaled)
  
  rescaled_trends <- rescaled_trends %>% 
    mutate(location = str_to_upper(location),
           location = str_replace_all(location,"-", " - "),
           location = str_replace_all(location,",", ""),
           location = str_replace_all(location,"\\s(\\w{2})\\b", " \\(\\1\\)")) %>% 
    select(DMA_google = location, !!keyword := hits_transformed_a, date)
  
  return(rescaled_trends)
}


```

```{r find_cross_sectional_trends}
find_cross_sectional_trends <- function(keyword, date_begin, span_length = 1){
  ppl <- as.character(ymd(date_begin) + span_length)

  print(glue("keyword = {keyword}"))
  print(glue("span = {date_begin} - {ppl}"))
  
  trends <- gtrends(
    keyword = keyword,
    geo = "US",
    time = paste(date_begin, ppl),
    gprop = "web",
    category = 0,
    hl = "en-US")$interest_by_dma %>%
    tibble() %>%
    mutate(date = date_begin,
           hits = as.numeric(hits)) %>% 
    select(-c(geo, gprop)) %>% 
    mutate(location = str_to_upper(location),
           location = str_replace_all(location,"-", " - "),
           location = str_replace_all(location,",", ""),
           location = str_replace_all(location,"\\s(\\w{2})\\b", " \\(\\1\\)"))
  
  return(trends)
  
}
```

# dma keys
```{r}
# bringing in DMA fox new search from
# https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/IVXEHT/A56RIW&version=7.4
dma <- read_csv(here("data", "county_dma.csv")) %>%
    mutate(FIPS_state = str_pad(STATEFP, 2, pad = "0"),
         FIPS_county = str_pad(CNTYFP, 3, pad = "0"),
         FIPS = paste0(FIPS_state, FIPS_county)) %>%
  select(FIPS, DMA, STATE, COUNTY)

# I made this file for the various inconsistencies between the two
dma_key <- read_csv(here("data","google_dma_key.csv")) 

dma <- dma %>%
  full_join(dma_key)
```


# attitudinal


## Vaccine Hesitancy
		○ https://data.cdc.gov/Vaccinations/Vaccine-Hesitancy-for-COVID-19-County-and-local-es/q9mh-h2tw/data
		○ https://data.cdc.gov/Vaccinations/Vaccine-Hesitancy-for-COVID-19-County-and-local-es/q9mh-h2tw
		
cross-sectional
dates - March 3, 2021 – March 15, 2021
```{r vacc_hes}
vacc_hes_data <- vroom(here('data', 'vaccine-hesitancy', 'Vaccine_Hesitancy_for_COVID-19__County_and_local_estimates.csv')) %>% 
  janitor::clean_names() %>% 
  mutate(fips = str_pad(fips_code, 5, pad = '0')) %>% 
  select(fips, county_name, vacc_hesitant = estimated_hesitant_or_unsure)

vacc_hes_gtrends <- find_cross_sectional_trends(c('covid conspiracy',
                                                  'COVID-19 vaccine',
                                                  'Coronavirus',
                                                  'Covid-19'
                                                  # URLdecode('%2Fg%2F11j8_9sv06'),
                                                  # URLdecode('%2Fg%2F11j2cc_qll')
                                                  ), 
                            '2021-03-03', 12) %>%   
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date) %>% 
  janitor::clean_names()

vacc_hes <- vacc_hes_data %>% 
  left_join(select(dma, FIPS, DMA_google), by = c('fips' = 'FIPS')) %>% 
  full_join(vacc_hes_gtrends, by = c('DMA_google' = 'location'))  

vacc_hes %>% 
  pivot_longer(cols = covid_conspiracy:covid_19) %>% 
  ggplot(aes(y = vacc_hesitant, x = value, color = name)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "lm") +
  facet_wrap(~ name)


write_rds(vacc_hes, here('data', 'cleaned_data', 'vacc_hes.rds'))
```

## Mask Usage
		○ New York Times Survey
		○ https://github.com/nytimes/covid-19-data/tree/master/mask-use

cross-sectional
July 2 and July 14, 2020
```{r Mask}

mask_data <- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/mask-use/mask-use-by-county.csv') %>% 
  rowwise() %>% 
  mutate(mask_rare = NEVER + RARELY) %>% 
  select(fips = COUNTYFP, mask_rare)

mask_gtrends <- find_cross_sectional_trends(c('Face mask',
                                              'Mask',
                                              # 'Civil and political rights',
                                              'Cloth face mask'
                                              ),
                                            '2020-07-02', 12)%>%   
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date) %>% 
  janitor::clean_names()

mask <- mask_data %>% 
  left_join(select(dma, FIPS, DMA_google), by = c('fips' = 'FIPS')) %>% 
  full_join(mask_gtrends, by = c('DMA_google' = 'location'))  

mask %>% 
  pivot_longer(cols = face_mask:civil_and_political_rights) %>% 
  ggplot(aes(y = mask_rare, x = value, color = name)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "lm") +
  facet_wrap(~ name)

write_rds(mask, here('data', 'cleaned_data', 'mask.rds'))

```





# health
## Covid Rates
		○ https://github.com/nytimes/covid-19-data/tree/master/rolling-averages
longitudinal
dates - 

```{r covid}
covid_rates <- vroom('https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-counties-2020.csv') %>% bind_rows(vroom('https://raw.githubusercontent.com/nytimes/covid-19-data/master/rolling-averages/us-counties-2021.csv')) %>% 
  mutate(wday = lubridate::wday(date, label=TRUE),
         fips = str_sub(geoid, start = -5)) %>% 
  filter(wday == "Mon",
         county != 'Unknown',
         !(state %in% c('Puerto Rico', 'Virgin Islands', 'Northern Mariana Islands'))) %>% 
  select(fips, date, county, state, covid_rate = cases_avg_per_100k)

covid_gtrend_2020 <- find_year_trends('Covid-19', 2020) 
covid_gtrend_2021 <- find_year_trends('Covid-19', 2021) 
covid_gtrend  <- covid_gtrend_2020 %>% bind_rows(covid_gtrend_2021) 

taste_gtrend_2020 <- find_year_trends('Taste Loss', 2020) 
taste_gtrend_2021 <- find_year_trends('Taste Loss', 2021) 
taste_gtrend  <- taste_gtrend_2020 %>% bind_rows(taste_gtrend_2021) 

smell_gtrend_2020 <- find_year_trends('Smell Loss', 2020) 
smell_gtrend_2021 <- find_year_trends('Smell Loss', 2021) 
smell_gtrend  <- smell_gtrend_2020 %>% bind_rows(smell_gtrend_2021) 

covid <- covid_rates %>% 
  inner_join(select(dma, FIPS, DMA_google), by = c('fips' = 'FIPS')) %>% 
  left_join(covid_gtrend, by = c('DMA_google', 'date')) %>% 
  left_join(taste_gtrend, by = c('DMA_google', 'date')) %>% 
  left_join(smell_gtrend, by = c('DMA_google', 'date')) %>% 
  janitor::clean_names()



covid %>% 
  filter(fips %in% c("08003", '55057', '51059', '39085', 
           # '36119',
           '34021', '12071', '04017')) %>% 
  pivot_longer(cols = c(covid_rate, covid_19, taste_loss, smell_loss)) %>% 
  ggplot(aes(x = date, y = value, group = name, color = name)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ glue('{county}, {state}'), scale = 'free_y') + 
  theme_minimal()

write_rds(covid, here('data', 'cleaned_data', 'covid.rds'))

```

## Suicide
		○ https://wonder.cdc.gov/mcd.html 
		○ Multiple Cause of Death Data 2019 (see notes for which variables count)
dates - 2019 cross sectional inclusive

```{r suicide}
suicide_measures_both <- read_delim(here('data','suicide',
                                    'Multiple Cause of Death, 1999-2020.txt')) %>% 
  janitor::clean_names() %>% 
  filter(is.na(notes)) %>% 
  select(fips = county_code, county, year = year_code, deaths_both = deaths, population)

suicide_measures_mcd <- read_delim(here('data','suicide',
                                    'Multiple Cause of Death, 1999-2020 only multiple cause.txt')) %>% 
  janitor::clean_names() %>% 
  filter(is.na(notes)) %>% 
  select(fips = county_code, county, year = year_code, deaths_mcd = deaths)

breaks <-  c(10,20,40,60,100,200,400,700,1300)
suicide_measures <- suicide_measures_both %>% 
  left_join(suicide_measures_mcd, by = c('fips', 'county', 'year')) %>% 
  mutate(deaths_mcd = na_if(deaths_mcd,'Missing'),
         deaths_both = na_if(deaths_both,'Missing'),
         deaths_mcd_supp = ifelse(deaths_mcd == 'Suppressed', '(0:9]', NA), 
         deaths_both_supp = ifelse(deaths_both == 'Suppressed', '(0:9]', NA), 
         deaths_mcd = na_if(deaths_mcd,'Suppressed'),
         deaths_both = na_if(deaths_both,'Suppressed'),
         deaths_mcd_cut = as.character(cut(as.numeric(deaths_mcd), breaks = breaks)),
         deaths_both_cut = as.character(cut(as.numeric(deaths_both), breaks = breaks)),
         deaths_mcd_cut = ifelse(!is.na(deaths_mcd_supp),
                                 deaths_mcd_supp,
                                 deaths_mcd_cut), 
         deaths_both_cut = ifelse(!is.na(deaths_both_supp),
                                  deaths_both_supp,
                                  deaths_both_cut)) %>% 
        select(fips, county, year, deaths_both_cut) %>% 
  mutate(deaths = factor(deaths_both_cut, ordered = T),
         deaths = fct_relevel(deaths, c("(0:9]",
                                        "(10,20]",
                                        "(20,40]", 
                                        "(40,60]",
                                        "(60,100]",    
                                        "(100,200]",
                                        "(200,400]",
                                        "(400,700]",   
                                        "(700,1.3e+03]")))
suicide_measures %>% 
  count(year, deaths) %>%
  ggplot(aes(x = deaths, y = n)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~year)        
  
  
append_years <- function(year_begin, year_end){
  years <- seq(year_begin,year_end,1)
  results <- tibble('location' = character(),
    'suicide' = numeric(), 
    'depression' = numeric(),
    'suicide hotline' = numeric(),
    'year' = numeric()
    )
  for (i in years){
    print(glue("finding trends for {i}..."))
    results <- find_cross_sectional_trends(c('suicide', 'depression', 'suicide hotline'),
                                glue("{i}-01-01"), 365) %>%
      pivot_wider(names_from = keyword, values_from = hits)  %>%
      select(-date) %>%
      mutate(year = i) %>% 
      bind_rows(results)
  }
  results
}  

suicide_gtrends <- append_years(2010, 2020)

suicide <- suicide_measures %>% 
  left_join(select(dma, FIPS, DMA_google), by = c('fips' = 'FIPS')) %>% 
  full_join(suicide_gtrends, by = c('DMA_google' = 'location', 'year' = 'year'))  %>% 
  janitor::clean_names()

write_rds(suicide, here('data', 'cleaned_data', 'suicide.rds'))

suicide %>% 
  filter(fips %in% c("08003", '55057', '51059', '39085', 
           # '36119',
           '34021', '12071', '04017')) %>% 
  mutate(`actual deaths` = as.numeric(deaths) * 10) %>% 
  pivot_longer(cols = c('suicide', 'depression', 'suicide_hotline', 'actual deaths')) %>% 
  ggplot(aes(x = year, y = value, group = name, color = name)) +
  geom_line() + 
  geom_point() +
  facet_wrap(~ glue('{county}'), scale = 'free_y') + 
  theme_minimal()



```


# political
• Presidential results
https://github.com/tonmcg/US_County_Level_Election_Results_08-20
```{r pres}
pres_2016_results <- read_csv('https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2016_US_County_Level_Presidential_Results.csv') %>% 
  select(county_name, county_fips = combined_fips, 
         totalvotes = total_votes, clinton = votes_dem, trump = votes_gop) %>% 
    mutate(county_fips = str_pad(county_fips, 5, pad = 0),
           clinton_p = clinton / totalvotes,
         trump_p = trump / totalvotes)


pres_2020_results <- read_csv('https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv') %>% 
  select(state = state_name, county_name, county_fips, 
         totalvotes = total_votes, biden = votes_dem, trump = votes_gop) %>% 
    mutate(biden_p = biden / totalvotes,
         trump_p = trump / totalvotes)

pres_2020_gtrend <- find_cross_sectional_trends(c('Joe Biden', 'Donald Trump'), '2020-01-01', 307) %>% 
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date)


pres_2016_gtrend <- find_cross_sectional_trends(c('Hilary Clinton', 'Donald Trump'), '2016-01-01', 307) %>% 
  pivot_wider(names_from = keyword, values_from = hits)  %>% 
  select(-date)

pres_2016 <- pres_2016_results %>% 
  inner_join(select(dma, FIPS, DMA_google), by = c('county_fips' = 'FIPS')) %>%
  left_join(pres_2016_gtrend, by = c('DMA_google' = 'location')) %>%
  select(dma = DMA_google,
         fips = county_fips, 
         clinton_p, `Hilary Clinton`, trump_p, `Donald Trump`)
  
pres_2016 %>% ggplot(aes(x = trump_p, y = `Donald Trump`)) + geom_jitter() + geom_smooth()
pres_2016 %>% ggplot(aes(x = clinton_p, y = `Hilary Clinton`)) + geom_jitter()

pres_2020 <- pres_2020_results %>% 
  inner_join(select(dma, FIPS, DMA_google), by = c('county_fips' = 'FIPS')) %>% 
  left_join(pres_2020_gtrend, by = c('DMA_google' = 'location')) %>% 
  select(dma = DMA_google,
         fips = county_fips, 
         biden_p, `Joe Biden`, trump_p, `Donald Trump`)

pres_2020 %>% ggplot(aes(x = biden_p, y = Joe Biden`)) + geom_jitter() + geom_smooth()
pres_2020 %>% ggplot(aes(x = trump_p, y = `Donald Trump`)) + geom_jitter() + geom_smooth()


rm(list = c("pres_2016_results", "pres_2016_gtrend",
            "pres_2020_results", "pres_2020_gtrend"))

write_rds(pres_2016, here('data', 'cleaned_data', 'pres_2016.rds'))
write_rds(pres_2020, here('data', 'cleaned_data', 'pres_2020.rds'))

