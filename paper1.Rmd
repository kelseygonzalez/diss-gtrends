---
title: "Article 1:	Construct Validity and Correspondence of Google Trends"
author: "Kelsey Gonzalez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: 72
output:
  bookdown::pdf_document2: 
    latex_engine: xelatex
    number_sections: true
  # bookdown::word_document2: 
  #   toc: true
  #   reference_docx: StylesTemplate.docx
header-includes:
   - \usepackage{siunitx}
   - \usepackage{setspace}
   - \usepackage{dcolumn}
   - \usepackage{longtable}
   - \usepackage{caption}
   - \usepackage{booktabs}
   - \usepackage{placeins}
   - \doublespacing
csl: american-sociological-association.csl
bibliography: "thesis.bib"
indent: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE,
                      fig.width = 7,
                      fig.asp = 0.8,
                      out.width = "80%",
                      fig.align="center"
                      )

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, glue, extrafont, here, jtools, psych,
               modelsummary, showtext, thematic, kableExtra, scales, nlme,
               flextable)

my_palette  <- c(MetBrewer::met.brewer(name = 'Cross', type = 'discrete'), '#555F61')

```
```{r data}
vacc_hes <- read_rds(here('data', 'cleaned_data', 'vacc_hes.rds'))
mask <- read_rds(here('data', 'cleaned_data', 'mask.rds')) %>%  ungroup()
covid <- read_rds(here('data', 'cleaned_data', 'covid.rds'))
suicide <- read_rds(here('data', 'cleaned_data', 'suicide.rds'))
pres_2016 <- read_rds(here('data', 'cleaned_data', 'pres_2016.rds'))
pres_2020 <- read_rds(here('data', 'cleaned_data', 'pres_2020.rds'))
covid_corrs <- read_rds(here('data', 'from_hpc', 'covid_corrs.rds'))
suicide_corrs <- read_rds(here('data', 'from_hpc', 'suicide_corrs.rds'))


```

# Abstract

Possible titles Digital Trace Data as Social Indicators: Indicators of
Attention Rather Than Support

**Keywords**:

# Intro

New big data sources have led to vast possibilities for social science
research because they are bigger, cheaper, and already available
[@kingEnsuringDataRichFuture2011; @lazerComputationalSocialScience2009;
@salganikBitBitSocial2017]. Before overenthusiastically embracing these
sources into our workflows, social scientists must clearly establish
parameters under which these data sources could be operationalized
[@bailCulturalEnvironmentMeasuring2014; @lazerParableGoogleFlu2014]. As
prior research outlined, the "quantity of data does not mean that one
can ignore foundational issues of measurement and construct validity and
reliability and dependencies among data" \[@lazerParableGoogleFlu2014,
p. 1203\]. Building on this prior research outlining these various
issues with big data [@boydCriticalQuestionsBig2012;
@lazerIssuesConstructValidity2015], this paper tests the construct
validity of Google Search Trends as an indicator of three different
cases, namely cultural attitudes, disease prevalence and voting
behavior. These three cases will be tested using cultural indicators
from the NORC General Social Survey, United States county-level suicide
rates from National Center for Health Statistics, US cases rates of
Covid-19 from The New York Times, historical US Presidential Election
results, and the American National Election Survey. Data will be
analyzed against corresponding operationalized Google Trends
longitudinal data using Pearson's r for pairwise correlations, testing
for the strength of relationships between the Google Trend indicator and
the respective comparison indicator. This paper will contribute to the
creation of methodological norms and standards of how to use Google
Trends as a big data source for societal research and serve as a
critical inquiry into the adoption of big data without a critical eye
for the ecological validity of the sources.

With the expansion of big data, some research has shown extremely
innovative methods that lead to groundbreaking results that are shown to
be reliable. As an example, @blumenstockPredictingPovertyWealth2015 use
county-level cell-phone records to construct the distribution of poverty
and wealth in Rwanda, a country where national surveys and censes are
rare and costly. However, @blumenstockPredictingPovertyWealth2015 go to
great lengths to demonstrate that their operationalization of the cell
phone data creates a reliable and valid construct; few social science
papers utilizing big data dig into the construct validity of their
metrics to this extent and even fewer publications focus on
methodological guidelines of how to use sources of big data
[@asseoTrackingCOVID19Using2020; @stilesAssessingCriterionValidity2018].
However, research has shown the small adjustments to an algorithm or
metric may void any research insight we are able to pull from such data
[@lazerParableGoogleFlu2014]. Because of this, I propose a
methodological validation study of the Google Search Trends source of
big data to investigate how it is advisable to utilize this data in
social scientific research.

I will use three categorizations of ways I propose Google Trends could
be operationalized for social scientific usage. First, I'll test Google
Trends as an operationalization of cultural attitudes with the General
Social Survey. After @bailCulturalEnvironmentMeasuring2014's call for
cultural sociologists to utilize the ever-expanding world of big data,
Google trends as a data source began appearing in sociological and
social science research. From research on mass shootings and firearms
[@brownsteinInternetSearchPatterns2020;
@semenzaInformationseekingWakeTragedy2020], protest and anti-Muslim
sentiment [@bailUsingInternetSearch2018;
@barrieSearchingRacismGeorge2020; @grossThereFergusonEffect2017], to
analyzing country-level changes in social perception [@reyes_etal18],
Google search trends are a new and innovative indicator of cultural
interest. Extending into social networks and culture,
@bailPrestigeProximityPrejudice2019 even used Google trends to measure
how culture spreads around the globe.

Google Search Trends have also been used continuously in estimations of
disease prevalence and population health in journals like the Journal of
Medical Internet Research. While much of this research has focused on
the Covid-19 pandemic [@jimenez_etal20;
@jimenezCOVID19SymptomGoogle2020;
@limEstimatingInformationSeekingBehaviour2020;
@mavraganiCOVID19PredictabilityUnited2020;
@nguyenGoogleTrendsAnalysis2020; @todorovaInternetBasedData2021] , other
research has investigated Google Trends as an indicator of wellbeing
[@brodeurCOVID19LockdownsWellbeing2021;
@carpiTwitterSubjectiveWellBeing2020; @duCOVID19IncreasesOnline2020],
suicidality [@burnettTimeTrendsPublic2020], vaccination uptake
[@dalumhansenEnsembleLearnedVaccination2016], obesity
[@sarigulNowcastingObesityUsing2014], and even insomnia
[@zittingGoogleTrendsReveal2020], to cover a few examples. For a partial
review of other utilizations, see @nutiUseGoogleTrends2014. According to
@jaidkaInformationseekingVsSharing2021, the majority of studies profess
a correlation of \> .70, "demonstrating the vast potential of Google
Search as a proxy for monitoring population health" (p. 3) based on
assumptions that individuals search because of self-diagnosis and to
identify possible courses of treatment
[@dechoudhurySeekingSharingHealth2014].

<!-- Following reports say that Google searches can predict covid  -->

<!-- 14. Brunori, P. & Resce, G. Searching for the peak Google Trends and the Covid-19 outbreak in Italy. SERIES working papers N. 04/2020 -->

<!-- Lampos, V. et al. Tracking COVID-19 using online search. Preprint at https://arxiv.org/abs/2003.08086 (2020). -->

<!-- 16. Walker, A., Hopkins, C. & Surda, P. The use of google trends to investigate the loss of smell related searches during COVID‐19 -->

<!-- outbreak. Int. Forum Allergy Rh. 10, 839–847 (2020). -->

<!-- 17. Stephens-Davidowitz, S. Google Searches Can Help Us Find Emerging Covid-19 Outbreaks. The New York Times https://www. -->

<!-- nytimes.com/2020/04/05/opinion/coronavirus-google-searches.html (2020). -->

<!-- 18. Frank, T. Goldman says fewer ‘loss of smell’ Google queries suggest better COVID outlook. Consumer News and Business Channel. CNBC https://www.cnbc.com/2020/04/15/goldman-says-fewer-loss-of-smell-google-searches-is-a-positive-sign-for-pande -->

<!-- mic.html (2020) -->

Various sources have also used Google Trends as a way to forecast
political elections and political attitudes
[@wolfTrendingRightDirection2018]. For instance,
@swearingenGoogleInsightsSenate2014 investigate how U.S. Senate
Elections relate to attention measured by search traffic.
@prado-romanGoogleTrendsPredictor2020 compare how Google Search trends
are able to predict presidential election results in both the United
States and Canada. Finally, the OECD Development Centre is investigating
how Google data can help elucidate governments' approval in Latin
America [@montoyaUsingGoogleData2020].

Research Question - How can we operationalize Google Search Trends as a
valid indicator for uses in social science research?

<https://journals.sagepub.com/doi/10.1177/0894439316631043> What
constructs might google trends capture and not capture well? Capture
attention but not attitudes

Also Asseo - "we assumed that media coverage may potentially decouple
the search popularity from the number of cases, since searches would
result not only from self-symptoms, but also from interest elicited by
media coverage."

# Research Methodology
To investigate the construct and criterion validity of the use of Google Trends
in these three areas, I gathered geo-located social science data across multiple
sources to address the three areas of inquiry for this paper.  Table
\@ref(tab:data-sources-table) outlines which data sources are used for this
project and which trends are matched to each source.

```{r data-sources-table}
#| results='asis'

data_sources <- tibble::tribble(
~type, ~Validated.Data.Source, ~Type, ~Dates, ~Google.Trends.Used,
"Behaviors and Attitudes","General Social Survey", "Cross-Sectional", "2010 - 2020", NA,
 
"Behaviors and Attitudes","Vaccine Hesitancy for COVID-19", "Cross-Sectional", "March 3 – 15, 2021", "covid conspiracy', 'COVID-19 vaccine', 'Coronavirus', 'Covid-19'",
 
"Behaviors and Attitudes","Mask-Wearing Survey Data", "Cross-Sectional", "July 2 - 14, 2020", "'Face Mask', 'Mask', 'Cloth Face Mask'",
 
"Health","Covid Rates", "Longitudinal", "Every Monday, 2020 - 2021", "'Covid-19', 'Coronavirus', 'Taste Loss', 'Smell Loss'",
 
"Health","County Suicide Rates", "Longitudinal", "Yearly 2010-2020", "'Suicide', 'Depression',' Suicide Hotline'",

'Political',"American National Election Survey", "Cross-Sectional", "2020", NA,
 
'Political',"Presidential Election Results", "Cross Sectional", "2016 & 2020", "'Hilary Clinton', 'Donald Trump', 'Joe Biden'"
 ) %>% as_grouped_data(groups = c("type"), columns = NULL)


data_sources %>% 
  as_flextable(hide_grouplabel = TRUE) %>% 
  set_caption(caption = "New York Air Quality Measurements")  %>% 
  # theming
  theme_box() %>% 
  bg(bg = my_palette[8], part = "header") %>% 
  color(color = "white", part = "header") %>%
  set_table_properties(layout = "autofit", width = 1) %>% 
  # grouped row style
  fontsize(size = 8) %>% 
  bold(i = ~ !is.na(type), bold = TRUE) %>% 
  italic(i = ~ !is.na(type), italic = TRUE) %>% 
  bg(i = ~ !is.na(type), bg = "#bad7db", part = "body")

```


## Measures
### Google Trends
This paper focuses on a validation of Google search trends [@googletrends].
Google trends portray the search frequency for specific search terms across
designated media markets areas (DMAs), a nonoverlapping aggregation of U.S.
counties to 210 media markets based on similar population clusters [@dma_key].
Raw data is on a scale from 0 to 100, with 100 being the maximum search
popularity out of all DMAs. Google Search Trend are now only available
cross-sectionally (a single time period across a geography) or as time-series (a
single geo-location across time). To remedy this and build a longitudinal
dataset of each search topic for the longitudinal datasets, I follow the method
proposed in @park_etal (p. 5). This method involves building a dataset of
unscaled cross-sectional values, selecting a DMA to use to establish the
rescaling ratio (I use 'Los Angeles CA'), and then finding the time-series
values for the one DMA. To find the rescaling ratio for each week in the
time-series, you divide the time-series value for each week by the
cross-sectional value for each week, resulting in a rescaling vector to be used
for all weeks in the dataset across geographies. To rescale each longitudinal
value, multiply the respective week's rescaling ratio by the cross-sectional
value. Rescaled longitudinal data was compared against time-series data for
multiple test counties and was equivalent. For a more in-depth explanation of
this procedure, see @park_etal (p. 5). Missing datapoints in longitudinal
datasets were filled in with interpolated values using `zoo::na.approx()`
[@zoo].


### attitudinal

<!-- [@gss_data] (let's see if I get access first) -->

One measure of attitudinal indicators is the Vaccine Hesitancy for COVID-19
[@vaches_data]. The CDC uses the U.S. Census Bureau’s Household Pulse Survey
(HPS) and the 2019 American Community Survey (ACS) 1-year Public Use Microdata
Sample (PUMS) to measure U.S. residents’ intentions to receive the COVID-19
vaccine if available during May 26, 2021 – June 7, 2021. This dataset consists
of `r nrow(vacc_hes)` observations, one for each U.S. County. The variable
measures the precent of adults in the county who describe themselves as
“unsure”, “probably not”, or “definitely not” going to get a COVID-19 vaccine
once one is available to them. The variable ranges from 
`r percent_format(0.01)(min(vacc_hes$vacc_hesitant))` to 
`r percent_format(0.01)(max(vacc_hes$vacc_hesitant))`. 

Another attitudinal indicator I use is the Mask-Wearing Survey Data conducted by
Dynata for the New York Times from July 2 through 14, 2020 [@mask_data]. 250,000
survey respondents were asked, "How often do you wear a mask in public when you
expect to be within six feet of another person?". The NYT weighted each response
to create a county level measure of what percent of the county never, rarely,
sometimes, frequently, and always wore a mask when in public. This dataset
consists of `r nrow(mask)` observations, one for each U.S. County. This measure
represents the percent of adults in the county who never or rarely wear a mask
(range = `r percent_format(0.01)(min(mask$mask_rare))` to 
`r percent_format(0.01)(max(mask$mask_rare))`)

### health

I also use U.S. Covid-19 rates to validate health and disease related topics. I
retrieve U.S. county-level Covid-19 rates from by @covid_data, who compile this
data based on reports from state and local health agencies. It is widely
acknowledged that there are biases in this data due to inconsistencies and
availability in testing as well as different community propensity to test
[@gu22; @cdc20a] However, it is the best measure we have of actual case rates.
Case Rate is measured as number of cases per 100,000 population. Observations
vary from a minimum of 0 to a maximum of `r max(covid$covid_rate)` for each 
Monday from `r glue("{format( min(covid$date), '%B %d, %Y')} through {format(max(covid$date), '%B %d, %Y')}")`.
There are `r nrow(covid)` cases across `r nrow(count(covid, fips))` 
counties and `r nrow(count(covid, date))` dates. Missing data were interpolated 
using `zoo::na.approx()` [@zoo].

I also use county-level suicide rates from the US Centers for Disease Control
and Prevention [-@suic_data]. Data is grouped by year from 2010-2020. Raw death
rates are scaled by population size for each year and can be interpreted as the
death rate by suicide for every 1000 people. There are `r nrow(suicide)` total
cases, resulting from `r nrow(count(suicide, year))` observations of `r
nrow(count(suicide, fips))` counties. Missing data were interpolated using
`zoo::na.approx()` [@zoo]. Measures range from 
`r round(min(suicide$death_rate, na.rm=T),3)` to 
`r round(max(suicide$death_rate, na.rm=T),3)`.

### political
Finally, I test Google Trends as an operationalization of political
attitudes by first looking at actual voting outcomes in historical US
Presidential Election results. This data comes from @pres_data, who scraped the
results from Townhall.com, Fox News, Politico, and the New York Times. Data on 
presidential outcomes were avaiable for `r nrow(pres_2016)` counties in 2016 and
`r nrow(pres_2020)` counties in 2020. Each variable measures the percent of votes
for the candidate, with the lowest percent at 
`r percent_format(0.01)(min(pres_2020$biden_p, na.rm=T))`
and the highest at `r percent_format(0.01)(max(pres_2020$biden_p, na.rm=T))`. 

In addition, I use data on political opinions from the the American National
Election Survey 2020 Time-Series Study [@anes_data]. This data is paired with
restricted data provided by ICPSR, the Inter-university Consortium for Political
and Social Research, that contains the geo-ids of the `r scales::label_comma()(5441)`
survey respondents. The study interviewed respondents in a pre-election survey
that was conducted between August 18, 2020 and the day of the US Presidential
election day, November 3, 2020.

<!-- TODO: WHICH VARIABLES -->
<!-- TODO: VARIABLE SCALE -->


### Other

In addition to specific outcomes of interest, I also gathered various county
controls to investigate possible variable confounding. The first Seven of these
variables come from the 2010-2019 5-year American Community Surveys [@acs2019;
@acs2018; @acs2017; @acs2016; @acs2015; @acs2014; @acs2013; @acs2012;
@acs2011; @acs2010]. These data include total population, population density,
unemployment rate for those 16 and over, median county income, average commute
time, percent of households living under the poverty line, and percent above 65
years old. In addition, some models employ the U.S. Current Population Survey &
American Community Survey Geographic Estimates of Internet Use, 1997-2018
[@internet_use] to estimate households with broadband internet subscriptions.
This final variable is an attempt to capture the latent propensity to use the
internet for information search.

<!-- ACS 5 year estimates -->
<!-- a00001 total population -->
<!-- a00002 population density -->
<!-- a17005 unemployment rate 16+ -->
<!-- a14006 median income -->
<!-- a09003 average commute time -->
<!-- poverty percent -->
<!-- 01001B 65 plus -->


## Analysis
Google Search Trends data and additional demographic data are merged with each
individual indicator based on County FIPS Codes and date. After creating these
different datasets, I use the Pearson correlation formula (formula
\@ref(eq:pearsoncorr)) for cross-sectional numeric data to calculate the
strength of the relationship between each Google Trend and the respective
data source.

\begin{equation}
 r =
  \frac{ \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) }{
        \sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}} (\#eq:pearsoncorr)
\end{equation}

To address longitudinal correlations, I employ Repeated Measures Correlation
using the `rmcorr` package in R [@bland1995; @bakdash2017]. Repeated Measures
Correlation is useful for determining the within-county association for paired
measures across time and counties. Results of these correlations can be seen in 
table \@ref(tab:corr-results).

As an additional test of the relationships, I employ multiple linear regression
(for cross-sectional datasets) and random intercept hierarchical linear models
[@pinheiro_etal21] (for longitudinal datasets) to identify the strength of
relationships across locales: I include city-data like county population size,
broadband rates, and median income to attempt to disentangle possible
confounders of the relationship between Google search Trends and verified
indicators. Identifying these possible confounded relationships will help to
explain why some articles find relationships between the trends and outcomes
while others did not. For linear regression models, I normalize independent
variables, i.e.variables have been centered and scaled to have a mean of 0 and
standard deviation 1.

# Results

## Cultural
```{r corr-results}
#|  results='asis'

options(knitr.kable.NA = '')

table2 <- tribble(
  ~'grp', ~'variable', ~'measure',~'trend1', ~'trend2', ~'trend3', ~'trend4', 
  "Vaccine Hesitancy", NA,  NA, 'covid_conspiracy', 'covid_19_vaccine', 'coronavirus', 'covid_19', 
  "Vaccine Hesitancy", "Vaccine Hesitancy", "Pearson's R Correlation",
  as.character(round(cor(vacc_hes$vacc_hesitant, vacc_hes$covid_conspiracy, use = "complete.obs"),4)),
  as.character(round(cor(vacc_hes$vacc_hesitant, vacc_hes$covid_19_vaccine, use = "complete.obs"),4)),
  as.character(round(cor(vacc_hes$vacc_hesitant, vacc_hes$coronavirus, use = "complete.obs"),4)),
  as.character(round(cor(vacc_hes$vacc_hesitant, vacc_hes$covid_19, use = "complete.obs"),4)),
  
  "Mask Attitudes",NA,  NA, 'face_mask', 'mask', 'cloth_face_mask',  NA,
  "Mask Attitudes","Mask Rare", "Pearson's R Correlation",
  as.character(round(cor(mask$mask_rare, mask$face_mask, use = "complete.obs"),4)),
  as.character(round(cor(mask$mask_rare, mask$mask, use = "complete.obs"),4)),
  as.character(round(cor(mask$mask_rare, mask$cloth_face_mask, use = "complete.obs"), 4)), NA,
  
  "Covid Rates",NA,  NA, 'covid_19',  'smell_loss', 'taste_loss', NA, 
  "Covid Rates","Covid Rate", "Pearson's R Correlation", 
  as.character(round(cor(covid$covid_rate, covid$covid_19, use = "complete.obs"),4)),
  as.character(round(cor(covid$covid_rate, covid$smell_loss, use = "complete.obs"),4)),
  as.character(round(cor(covid$covid_rate, covid$taste_loss, use = "complete.obs"),4)),
  NA,
  "Covid Rates","Covid Rate", "rmcorr", 
  as.character(covid_corrs[[2,2]]), 
  as.character(covid_corrs[[2,3]]), 
  as.character(covid_corrs[[2,4]]), NA,
  
  "Suicide Rates",NA,  NA, 'suicide', 'depression', 'suicide_hotline', NA, 
  "Suicide Rates","Suicide Rate", "Pearson's R Correlation",
  as.character(round(cor(suicide$death_rate, suicide$suicide, use = "complete.obs"),4)),
  as.character(round(cor(suicide$death_rate, suicide$depression, use = "complete.obs"),4)),
  as.character(round(cor(suicide$death_rate, suicide$suicide_hotline, use = "complete.obs"),4)),
  NA,
  "Suicide Rates","Suicide Rate", "rmcorr", 
  as.character(suicide_corrs[[2,2]]), 
  as.character(suicide_corrs[[2,3]]), 
  as.character(suicide_corrs[[2,4]]), NA,
  
  "2016 Presidential Votes",NA,  NA, 'Hilary Clinton',  'Donald Trump', NA, NA,
  "2016 Presidential Votes","2016 Votes for Clinton", "Pearson's R Correlation",
  as.character(round(cor(pres_2016$clinton_p, pres_2016$`Hilary Clinton`, use = "complete.obs"),4)),
  as.character(round(cor(pres_2016$clinton_p, pres_2016$`Donald Trump`, use = "complete.obs"),4)), NA, NA,
  "2016 Presidential Votes","2016 Votes for Trump", "Pearson's R Correlation",
  as.character(round(cor(pres_2016$trump_p, pres_2016$`Hilary Clinton`, use = "complete.obs"),4)),
  as.character(round(cor(pres_2016$trump_p, pres_2016$`Donald Trump`, use = "complete.obs"),4)), NA, NA,
  
  "2016 Presidential Votes",NA,  NA, 'Joe Biden',  'Donald Trump', NA, NA,
  "2016 Presidential Votes","2020 Votes for Biden", "Pearson's R Correlation",
  as.character(round(cor(pres_2020$biden_p, pres_2020$`Joe Biden`, use = "complete.obs"),4)),
  as.character(round(cor(pres_2020$biden_p, pres_2020$`Donald Trump`, use = "complete.obs"),4)), NA, NA,
  "2016 Presidential Votes","2020 Votes for Trump", "Pearson's R Correlation",
  as.character(round(cor(pres_2020$trump_p, pres_2020$`Joe Biden`, use = "complete.obs"),4)),
  as.character(round(cor(pres_2020$trump_p, pres_2020$`Donald Trump`, use = "complete.obs"),4)), NA, NA
)  %>%   
  select(grp, measure, variable, trend1, trend2, trend3, trend4) %>% 
  as_grouped_data(groups = c("grp"), columns = NULL)

as_flextable(table2, hide_grouplabel = TRUE) %>% 
  set_caption(caption = "Correlation Results")  %>% 
  # theming
  theme_box() %>% 
  bg(bg = my_palette[8], part = "header") %>% 
  color(color = "white", part = "header") %>%
  set_table_properties(layout = "autofit", width = 1) %>% 
  # grouped row style
  fontsize(size = 8) %>% 
  bold(i = ~ !is.na(grp), bold = TRUE) %>% 
  italic(i = ~ !is.na(grp), italic = TRUE) %>% 
  bg(i = ~ !is.na(grp), bg = "#bad7db", part = "body")
```

The first attitudinal indicators is Vaccine Hesitancy for COVID-19 vaccines
[@vaches_data]. When comparing the measure of vaccine hesitancy to four
different Google Search Trends, the correlation does not exceed -0.4021
('Coronavirus' and vaccine hesitancy). Correlation's under |0.40| are considered
to be weak according to the common rules of thumb. When running these
correlations in multiple linear regression (see the results in table 
\@ref(tab:vacc_hes_analysis)), I see an $r^2$ of 0.221 (Model 1)
and 0.346 (Model 2), indicating that the Google Trends are able to explain about
22% of the variation in Vaccine Hesitancy alone. Demographic characteristics
like the percentage of households with broadband internet and the population
density are able to explain about 35% of the variation (model 3), outperforming
the first two models. The Trend coefficients themselves, however, are
significant and remain significant when controlling for demographics. This
reinforces the finding from the Pearson Correlation that there is a significant
but weak relationship between the Google Trends and Vaccine Hesitancy.

```{r vacc_hes_analysis}
#| tab.cap = "Linear Regression Results for Vaccine Hesitancy",
#|  results='asis'


vacc_hes <- vacc_hes %>% 
  select(-c(DMA_google, Geo_QName)) %>% 
  mutate(across(covid_conspiracy:broadband  , ~ scale(.x, center=TRUE, scale=TRUE)[,1]))

vacc_hes_1  <- lm(vacc_hesitant  ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + broadband,
                  data = vacc_hes)
vacc_hes_2 <- lm(vacc_hesitant  ~  covid_19_vaccine +     
                   coronavirus +covid_19,
                 data = vacc_hes)
vacc_hes_2b <- lm(vacc_hesitant  ~ covid_conspiracy + covid_19_vaccine +
                    coronavirus +covid_19,
                  data = vacc_hes)
vacc_hes_3  <- lm(vacc_hesitant  ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + broadband + 
                    covid_19_vaccine +
                    coronavirus +covid_19,
                   data = vacc_hes)

modelsummary(list(vacc_hes_2, vacc_hes_2b, vacc_hes_1, vacc_hes_3), 
             # title = "Linear Regression Results for Vaccine Hesitancy",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE'
             ) %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)


```

The second attitudinal measure I test is how Google Trends relates to rare mask
usage. As with vaccine hesitancy, the Pearson correlations are weak, if not 
negligible. I introduce these trends in multiple linear regression in table 
\@ref(tab:mask_analysis). Model 1 demonstrates that these three Google Search
Trends can explain about 9% of the variance in mask usage across U.S. counties,
reinforcing the conclusion that the relationship is quite weak. The coefficients
themselves are somewhat significant in Model 1. However, after including the
demographic varaibles in Models 2 and 3, we see that the relationship between
the Google Search Trends and mask usage is strengthed in magnitude and in
significance, likely indicating a repression effect due to background
relationships between the trends and demograhic variables. While the trends are
significant and match the magnitude of the demographic variables, the low $r^2$ 
for the trends still provides evidence that Google Search Trends data cannot 
replace survey analysis when trying to measure rare mask usage. 


```{r mask_analysis}
#|  results='asis',
#| tab.cap = "Linear Regression Results for Rare Mask Usage"

mask <- mask %>% 
  select(-c(DMA_google, Geo_QName)) %>% 
  mutate(across(face_mask:broadband  , ~ scale(.x, center=TRUE, scale=TRUE)[,1]))


mask_1  <- lm(mask_rare  ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + broadband,
                  data = mask)
mask_2 <- lm(mask_rare  ~  face_mask + mask + cloth_face_mask,
                 data = mask)
mask_3  <- lm(mask_rare  ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + broadband + 
                    face_mask + mask + cloth_face_mask,
                   data = mask)

modelsummary(list(mask_2, mask_1, mask_3), 
             # title = "Linear Regression Results for Rare Mask Usage",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE') %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)

```


## Medical


```{r covid_analysis}
covid <- covid %>% 
  select(-c(dma_google, Geo_QName, county, state)) %>% 
  mutate(across(covid_19:broadband  , ~ scale(.x, center=TRUE, scale=TRUE)[,1])) %>% 
  left_join(covid %>%
              group_by(fips) %>%
              summarize(covid_rate_fips_mean = mean(covid_rate, na.rm = TRUE)),
            by = "fips") %>% 
  drop_na(covid_rate)


covid_1  <- lme(covid_rate  ~ 
                  total_pop + pop_density + unemployment_rate + 
                  over_65 + poverty_rate + median_income + broadband +
                  covid_rate_fips_mean + date,
                random = ~ 1 | fips, na.action=na.omit,data = covid)
covid_2 <- lme(covid_rate  ~  
                 covid_19 + smell_loss + taste_loss + covid_rate_fips_mean  + 
                 date,
               random = ~ 1 | fips, na.action=na.omit, data = covid)
covid_3  <- lme(covid_rate  ~ 
                  total_pop + pop_density + unemployment_rate + 
                  over_65 + poverty_rate + median_income + broadband + 
                  covid_19 + smell_loss + taste_loss + covid_rate_fips_mean  +
                  date,
                random = ~ 1 | fips, na.action=na.omit, data = covid)

modelsummary(list(covid_2, covid_1, covid_3), 
             # title = "Hierarchical Model for Covid Case Rates",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).',
                      'Random intercept per county'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE') %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)

# TODO Drop SD intercept and observations,

```
pearson correlations
rmcorr
rsquared
coefficients
conclusion


```{r suicide_analysis}
suicide <- suicide %>% 
  select(-c(dma_google, Geo_QName, county, population, deaths)) %>% 
  mutate(across(suicide:broadband  , ~ scale(.x, center=TRUE, scale=TRUE)[,1])) %>% 
  left_join(suicide %>%
              group_by(fips) %>%
              summarize(death_rate_fips_mean = mean(death_rate , na.rm = TRUE)),
            by = "fips") %>% 
  drop_na(death_rate )


suicide_1  <- lme(death_rate   ~ 
                  total_pop + pop_density + unemployment_rate + 
                  over_65 + poverty_rate + median_income + broadband +
                  death_rate_fips_mean + year,
                random = ~ 1 | fips, na.action=na.omit,data = suicide)
suicide_2 <- lme(death_rate   ~  
                 suicide + depression + suicide_hotline + death_rate_fips_mean  + 
                 year,
               random = ~ 1 | fips, na.action=na.omit, data = suicide)
suicide_3  <- lme(death_rate   ~ 
                  total_pop + pop_density + unemployment_rate + 
                  over_65 + poverty_rate + median_income + broadband + 
                  suicide + depression + suicide_hotline + death_rate_fips_mean  +
                  year,
                random = ~ 1 | fips, na.action=na.omit, data = suicide)

modelsummary(list(suicide_2, suicide_1, suicide_3), 
             # title = "Hierarchical Model for Suicide Rates",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).',
                      'Random intercept per county'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE') %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)

# TODO Drop SD intercept and observations,
# TODO why is the r2 so high? death_rate_fips_mean?
```
pearson correlations
rmcorr
rsquared
coefficients
conclusion


## Political


```{r pres_2016_analysis}
pres_2016 <- pres_2016 %>% 
  select(-c(Geo_QName, dma)) %>% 
  mutate(across(c(`Hilary Clinton`,`Donald Trump`:broadband)  , ~ scale(.x, center=TRUE, scale=TRUE)[,1]))

vacc_hes_1a  <- lm(clinton_p   ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income,
                  data = pres_2016)
vacc_hes_2a <- lm(clinton_p   ~  `Donald Trump` + `Hilary Clinton`,
                 data = pres_2016)

vacc_hes_3a  <- lm(clinton_p   ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + 
                     `Donald Trump` + `Hilary Clinton`,
                   data = pres_2016)

vacc_hes_1b  <- lm(trump_p    ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income,
                  data = pres_2016)
vacc_hes_2b <- lm(trump_p    ~  `Donald Trump` + `Hilary Clinton`,
                 data = pres_2016)

vacc_hes_3b  <- lm(trump_p    ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + 
                     `Donald Trump` + `Hilary Clinton`,
                   data = pres_2016)

modelsummary(list(vacc_hes_2a,vacc_hes_1a, vacc_hes_3a 
                  # ,vacc_hes_1b, vacc_hes_2b,vacc_hes_3b
                  ), 
             # title = "Linear Regression Results for 2016 Presidential Election Results (Hilary Clinton Shown)",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).',
                      'Results predicting Donald J. Trump percentage largely equivalent and available upon request.'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE'
             ) %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)


```
pearson correlations
rsquared
coefficients
conclusion

```{r pres_2020_analysis}
pres_2020 <- pres_2020 %>% 
  select(-c(Geo_QName, dma)) %>% 
  mutate(across(c(`Joe Biden`,`Donald Trump`:broadband)  , ~ scale(.x, center=TRUE, scale=TRUE)[,1]))

vacc_hes_1a  <- lm(biden_p   ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income,
                  data = pres_2020)
vacc_hes_2a <- lm(biden_p   ~  `Donald Trump` + `Joe Biden`,
                 data = pres_2020)

vacc_hes_3a  <- lm(biden_p   ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + 
                     `Donald Trump` + `Joe Biden`,
                   data = pres_2020)

vacc_hes_1b  <- lm(trump_p    ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income,
                  data = pres_2020)
vacc_hes_2b <- lm(trump_p    ~  `Donald Trump` + `Joe Biden`,
                 data = pres_2020)

vacc_hes_3b  <- lm(trump_p    ~ 
                    total_pop + pop_density + unemployment_rate + 
                    over_65 + poverty_rate + median_income + 
                     `Donald Trump` + `Joe Biden`,
                   data = pres_2020)

modelsummary(list(vacc_hes_2a, vacc_hes_1a, vacc_hes_3a 
                  # ,vacc_hes_1b, vacc_hes_2b,vacc_hes_3b
                  ), 
             # title = "Linear Regression Results for 2020 Presidential Election Results (Joe Biden Shown)",
             notes= c('* p < .05. ** p < .01. *** p < .001 (two-tailed test).',
                      'Results predicting Donald J. Trump percentage largely equivalent and available upon request.'),
             estimate = "{estimate}{stars}",
             gof_omit = 'AIC|BIC|ICC|RMSE'
             ) %>%
  kable_styling(latex_options = c("hold_position", 'condensed'),
                font_size = 8)


```
pearson correlations
rsquared
coefficients
conclusion


# Discussion

While I expect these tests to show high correlation between observed
indicators and Google search trends, there will be three important
questions that surface. First, just because something is correlated,
does that mean it can replace the collection of other types of data?
Second, how correlated does a trend need to be for social scientists to
justifiably rely on it to indicate some outcome? And finally, how can we
construct analyses like this to be robust to changes in the terms used
across time and location?

The purpose of this paper is more methodological than theoretical, and I
see this paper having an impact on the social sciences and computational
social science as researchers pursue more projects using this source of
big data. Google Trends are relatively underutilized in the field
compared to in the health sciences and business. Once I assess how this
data can be used, I would like to be able to join
@bailCulturalEnvironmentMeasuring2014 in encouraging social scientists
to pursue more research with big data while taking into account the
potential pitfalls with any source of big data
[@mcfarlandBigDataDanger2015].

# Conclusion

\newpage

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix
